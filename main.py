import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import seaborn as sns

def process_fraud_data(df):
    df = df[(df['QuantitÃ© d\'acte - Prestation seule (pas presta. de rÃ©f.)'] > 0) &
            (df['Montant de la dÃ©pense - Prestation seule'] > 0)]
    
    df['DÃ©lai prescription-facturation'] = (
        (df['AnnÃ©e de remboursement'] - df['AnnÃ©e de prescription']) * 12 +
        (df['Mois de remboursement'] - df['Mois de prescription'])
    )
    
    remboursements_par_mois = df.groupby(
        ['NÂ° PS exÃ©cutant Statistique', 'AnnÃ©e de remboursement', 'Mois de remboursement']
    )['Nombre de bÃ©nÃ©ficiaires'].sum().reset_index(name='BÃ©nÃ©ficiaires par mois')
    df = df.merge(remboursements_par_mois, on=['NÂ° PS exÃ©cutant Statistique', 'AnnÃ©e de remboursement', 'Mois de remboursement'])
    
    depenses_par_mois = df.groupby(
        ['NÂ° PS exÃ©cutant Statistique', 'AnnÃ©e de remboursement', 'Mois de remboursement']
    )['Montant de la dÃ©pense - Prestation seule'].sum().reset_index(name='DÃ©penses par mois')
    df = df.merge(depenses_par_mois, on=['NÂ° PS exÃ©cutant Statistique', 'AnnÃ©e de remboursement', 'Mois de remboursement'])
    
    proportion_jeunes = df.groupby('NÂ° PS exÃ©cutant Statistique')['Age du bÃ©nÃ©ficiaire'].apply(lambda x: (x < 18).mean())
    df = df.merge(proportion_jeunes.rename('Proportion jeunes'), on='NÂ° PS exÃ©cutant Statistique')
    
    df['Age supÃ©rieur Ã  18'] = (df['Age du bÃ©nÃ©ficiaire'] > 18).astype(int)
    df = df[df['DÃ©lai prescription-facturation'] <= 8]
    
    prescripteurs_par_etablissement = df.groupby('NÂ° PS exÃ©cutant Statistique')['NÂ° PS prescripteur Statistique'].nunique().reset_index()
    prescripteurs_par_etablissement.columns = ['NÂ° PS exÃ©cutant Statistique', 'Nombre de prescripteurs']
    df = df.merge(prescripteurs_par_etablissement, on='NÂ° PS exÃ©cutant Statistique', how='left')
    
    prescripteurs_orl = df[df['LibellÃ© spÃ©cialitÃ©/nat. activitÃ© du PS prescripteur'] == 'OTO RHINO-LARYNGOLOGIE'] \
        .groupby('NÂ° PS exÃ©cutant Statistique')['NÂ° PS prescripteur Statistique'].nunique().reset_index()
    prescripteurs_orl.columns = ['NÂ° PS exÃ©cutant Statistique', 'Nombre de prescripteurs ORL']
    df = df.merge(prescripteurs_orl, on='NÂ° PS exÃ©cutant Statistique', how='left')
    
    df['Pourcentage ORL'] = (df['Nombre de prescripteurs ORL'] / df['Nombre de prescripteurs']) * 100
    df['Pourcentage autres'] = 100 - df['Pourcentage ORL']
    
    df = df.drop_duplicates()
    df['Moyenne Ã¢ge par Ã©tablissement'] = df.groupby('NÂ° PS exÃ©cutant Statistique')['Age du bÃ©nÃ©ficiaire'].transform('mean')
    
    return df

def process_location_data(df1, df2):

    df2['Latitude moyenne'] = (
    (df2['Latitude la plus au nord'] + df2['Latitude la plus au sud']) / 2
        )
    df2['Longitude moyenne'] = (
    (df2['Longitude la plus Ã  lâ€™est'] + df2['Longitude la plus Ã  lâ€™ouest']) / 2
        )

    # Renommer les colonnes pour correspondre aux noms des dÃ©partements
    departments_benef = df2.rename(columns={
        'Departement': 'DÃ©partement du bÃ©nÃ©ficiaire',
        'Latitude moyenne': 'Latitude bÃ©nÃ©ficiaire',
        'Longitude moyenne': 'Longitude bÃ©nÃ©ficiaire'
    })
    departments_execut = df2.rename(columns={
        'Departement': "DÃ©partement d'exercice du PS exÃ©cutant",
        'Latitude moyenne': 'Latitude exÃ©cutant',
        'Longitude moyenne': 'Longitude exÃ©cutant'
    })

    print(departments_benef.columns)
    
    # Correction des codes dÃ©partementaux pour la Corse
    departments_benef.loc[departments_benef['DÃ©partement du bÃ©nÃ©ficiaire'] == '2A', 'DÃ©partement du bÃ©nÃ©ficiaire'] = "200"
    departments_benef.loc[departments_benef['DÃ©partement du bÃ©nÃ©ficiaire'] == '2B', 'DÃ©partement du bÃ©nÃ©ficiaire'] = "201"
    
    departments_execut.loc[departments_execut["DÃ©partement d'exercice du PS exÃ©cutant"] == '2A', "DÃ©partement d'exercice du PS exÃ©cutant"] = "200"
    departments_execut.loc[departments_execut["DÃ©partement d'exercice du PS exÃ©cutant"] == '2B', "DÃ©partement d'exercice du PS exÃ©cutant"] = "201"
    
    # Convertir en entier
    departments_benef['DÃ©partement du bÃ©nÃ©ficiaire'] = departments_benef['DÃ©partement du bÃ©nÃ©ficiaire'].astype(int)
    departments_execut["DÃ©partement d'exercice du PS exÃ©cutant"] = departments_execut["DÃ©partement d'exercice du PS exÃ©cutant"].astype(int)
    
    # Fusion des donnÃ©es de localisation
    df1 = df1.merge(departments_benef, on='DÃ©partement du bÃ©nÃ©ficiaire', how='left')
    df1 = df1.merge(departments_execut, on="DÃ©partement d'exercice du PS exÃ©cutant", how='left')
    
    # Calcul de la distance bÃ©nÃ©ficiaire - Ã©tablissement
    def haversine(lat1, lon1, lat2, lon2):
        R = 6371  # Rayon de la Terre en km
        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2
        c = 2 * np.arcsin(np.sqrt(a))
        return R * c
    
    df1['Distance benef ex (km)'] = haversine(
        df1['Latitude bÃ©nÃ©ficiaire'],
        df1['Longitude bÃ©nÃ©ficiaire'],
        df1['Latitude exÃ©cutant'],
        df1['Longitude exÃ©cutant']
    )
    
    # Filtrage sur les distances
    df1['Distance benef ex (km)'] = df1['Distance benef ex (km)'].apply(
        lambda x: 0 if x < 50 else x
    )
    
    return df1

def main():
    st.set_page_config(page_title="Application de DÃ©tection AvancÃ©e", layout="wide")
    st.header("ğŸ” Analyse des Comportements Anormaux dans les DonnÃ©es d'AudioprothÃ¨ses")
    st.markdown("Veuillez tÃ©lÃ©verser deux fichiers CSV : votre jeu de donnÃ©es principal et le fichier de correspondance des rÃ©gions.")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("TÃ©lÃ©versement du Jeu de DonnÃ©es Principal")
        file1 = st.file_uploader("Choisir le premier fichier CSV", type="csv", key="file1")
        
    with col2:
        st.subheader("TÃ©lÃ©versement du Fichier de Correspondance RÃ©gionale")
        file2 = st.file_uploader("Choisir le second fichier CSV", type="csv", key="file2")

    if file1 is not None and file2 is not None:
        df1 = pd.read_csv(file1)
        df2 = pd.read_csv(file2)

        df1 = process_fraud_data(df1)
        df1 = process_location_data(df1, df2)

        tab1, tab2, tab3 = st.tabs(["AperÃ§u des DonnÃ©es", "Analyse AvancÃ©e", "Visualisations"])

        with tab1:
            st.subheader("ğŸ“Œ AperÃ§u du Jeu de DonnÃ©es")
            st.write(df1.head())
            
            st.subheader("ğŸ“Š Statistiques Descriptives")
            st.write(df1.describe())

        with tab2:
            st.header("ğŸš¨ Tableau de Bord d'Analyse AvancÃ©e")
            st.markdown("---")

            st.subheader("ğŸ›ï¸ SÃ©lection des Variables")
            all_features = [
                'DÃ©lai prescription-facturation',
                'BÃ©nÃ©ficiaires par mois',
                'DÃ©penses par mois',
                'QuantitÃ© d\'acte - Prestation seule (pas presta. de rÃ©f.)',
                'Montant de la dÃ©pense - Prestation seule',
                'Proportion jeunes',
                'Age supÃ©rieur Ã  18',
                'Moyenne Ã¢ge par Ã©tablissement',
                'Distance benef ex (km)',
                'Nombre de prescripteurs',
                'Pourcentage ORL',
                'Pourcentage autres'
            ]

            selected_features = st.multiselect(
                "ğŸ”§ SÃ©lectionnez les variables Ã  analyser :",
                all_features,
                default=all_features
            )

            if st.button("ğŸš€ Lancer l'Analyse"):
                with st.spinner("ğŸ” Analyse en cours..."):
                    st.markdown("---")
                    st.header("ğŸ“ˆ RÃ©sultats de l'Analyse AvancÃ©e")

                    df1[selected_features] = df1[selected_features].fillna(df1[selected_features].mean())

                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(df1[selected_features])

                    model = IsolationForest(contamination=0.01, random_state=42)
                    df1['Anomalie'] = model.fit_predict(X_scaled)
                    df1['Score_Anomalie'] = model.decision_function(X_scaled)

                    df1['Anomalie'] = df1['Anomalie'].map({1: 0, -1: 1})

                    st.session_state.anomalies = df1[df1['Anomalie'] == 1]
                    st.session_state.normales = df1[df1['Anomalie'] == 0]

                    st.subheader("ğŸ“Š RÃ©sumÃ© de l'Analyse")
                    col1, col2, col3 = st.columns(3)
                    col1.metric("ğŸ’¼ Total des Transactions", len(df1))
                    col2.metric("âš ï¸ Anomalies Potentielles", df1['Anomalie'].sum())

                    perte_potentielle = df1[df1['Anomalie'] == 1]['Montant de la dÃ©pense - Prestation seule'].sum()
                    col3.metric("ğŸ’° Estimation des Pertes Potentielles", f"â‚¬ {perte_potentielle:,.2f}")

                    st.subheader("ğŸ” CaractÃ©ristiques des Anomalies")
                    anomalies = df1[df1['Anomalie'] == 1]
                    normales = df1[df1['Anomalie'] == 0]

                    st.markdown("**ğŸ“Š Comparaison des Moyennes**")
                    compare_df = pd.DataFrame({
                        'Normal': normales[selected_features].mean(),
                        'Anomalie': anomalies[selected_features].mean()
                    }).style.format("{:.2f}")
                    st.dataframe(compare_df)

                    st.subheader("ğŸ”¥ Anomalies les Plus Significatives")
                    anomalies_sorted = anomalies.sort_values(by='Score_Anomalie', ascending=True)
                    st.dataframe(anomalies_sorted.head(10)[['NÂ° PS exÃ©cutant Statistique', 'Score_Anomalie'] + selected_features])

                    st.subheader("ğŸ“Š CorrÃ©lation entre les Anomalies et les Variables SÃ©lectionnÃ©es")
                    correlation_matrix = anomalies[selected_features].corr()

                    plt.figure(figsize=(10, 8))
                    sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f", cbar=True, linewidths=0.5)
                    plt.title("CorrÃ©lation entre les Variables et les Anomalies", fontsize=16)
                    st.pyplot(plt)

        with tab3:
            if 'anomalies' in st.session_state and 'normales' in st.session_state:
                anomalies = st.session_state.anomalies
                normales = st.session_state.normales

                # CrÃ©ation des sous-tabs
                sub_tab1, sub_tab2, sub_tab3 = st.tabs(["Indicateurs et comparaisons", "Analyse de rÃ©gions", "Analyse d'Ã©tablissements"])

                with sub_tab1:  # Indicateurs et comparaisons
                    st.write("Comparaison du DÃ©lai prescription-facturation")
                    mean_anomalies = anomalies['DÃ©lai prescription-facturation'].mean()
                    mean_normales = normales['DÃ©lai prescription-facturation'].mean()
                    categories = ['Anomalies', 'Normales']
                    means = [mean_anomalies, mean_normales]

                    fig, ax = plt.subplots(figsize=(10, 6))
                    colors = ['#1f77b4', '#ff7f0e']
                    bars = ax.barh(categories, means, color=colors, edgecolor='black', linewidth=1.2)

                    for bar in bars:
                        ax.text(bar.get_width() + 0.05, bar.get_y() + bar.get_height()/2,
                                f'{bar.get_width():.2f}', va='center', ha='left', fontsize=12, color='black')

                    ax.set_xlabel("Moyenne du DÃ©lai prescription-facturation", fontsize=14)
                    ax.set_ylabel("CatÃ©gories", fontsize=14)
                    ax.set_title("Comparaison des Moyennes du DÃ©lai prescription-facturation", fontsize=16, fontweight='bold')
                    ax.set_facecolor('whitesmoke')
                    for spine in ax.spines.values():
                        spine.set_linewidth(1.5)
                        spine.set_color('gray')

                    st.pyplot(fig)
                    
                    
                    st.write("Distribution des Distances dans les Anomalies")
                    fig, ax = plt.subplots(figsize=(10, 6))
                    sns.histplot(anomalies['Distance benef ex (km)'], bins=30, kde=True, color='orange', ax=ax)
                    ax.set_title("Distribution des Distances (Anomalies)", fontsize=16)
                    ax.set_xlabel("Distance benef ex (km)", fontsize=12)
                    ax.set_ylabel("FrÃ©quence", fontsize=12)

                    st.pyplot(fig)

                with sub_tab2:  # Analyse de rÃ©gions
                    st.write("RÃ©partition des DÃ©partements dans les Anomalies")
                    top_departments = anomalies['DÃ©partement d\'exercice du PS exÃ©cutant'].value_counts().head(5)

                    fig, ax = plt.subplots(figsize=(8, 6))
                    ax.pie(top_departments, labels=top_departments.index, autopct='%1.1f%%', startangle=90, wedgeprops={'width': 0.3})
                    centre_circle = plt.Circle((0, 0), 0.50, color='white', fc='white', lw=0)
                    ax.add_artist(centre_circle)
                    ax.set_title("RÃ©partition des DÃ©partements (Anomalies)", fontsize=14)

                    st.pyplot(fig)

                    # Mapping des dÃ©partements vers les rÃ©gions
                    departement_to_region = {
                        '01': 'Auvergne-RhÃ´ne-Alpes', '02': 'Hauts-de-France', '03': 'Auvergne-RhÃ´ne-Alpes', '04': 'Provence-Alpes-CÃ´te d\'Azur',
                        '05': 'Provence-Alpes-CÃ´te d\'Azur', '06': 'Provence-Alpes-CÃ´te d\'Azur', '07': 'Auvergne-RhÃ´ne-Alpes', '08': 'Grand Est',
                        '09': 'Occitanie', '10': 'Grand Est', '11': 'Occitanie', '12': 'Occitanie', '13': 'Provence-Alpes-CÃ´te d\'Azur', '14': 'Normandie',
                        '15': 'Auvergne-RhÃ´ne-Alpes', '16': 'Nouvelle-Aquitaine', '17': 'Nouvelle-Aquitaine', '18': 'Centre-Val de Loire', '19': 'Nouvelle-Aquitaine',
                        '20': 'Corse', '21': 'Bourgogne-Franche-ComtÃ©', '22': 'Bretagne', '23': 'Nouvelle-Aquitaine', '24': 'Nouvelle-Aquitaine', '25': 'Bourgogne-Franche-ComtÃ©',
                        '26': 'Auvergne-RhÃ´ne-Alpes', '27': 'Normandie', '28': 'Centre-Val de Loire', '29': 'Bretagne', '30': 'Occitanie', '31': 'Occitanie',
                        '32': 'Occitanie', '33': 'Nouvelle-Aquitaine', '34': 'Occitanie', '35': 'Bretagne', '36': 'Centre-Val de Loire', '37': 'Centre-Val de Loire',
                        '38': 'Auvergne-RhÃ´ne-Alpes', '39': 'Bourgogne-Franche-ComtÃ©', '40': 'Nouvelle-Aquitaine', '41': 'Centre-Val de Loire', '42': 'Auvergne-RhÃ´ne-Alpes',
                        '43': 'Auvergne-RhÃ´ne-Alpes', '44': 'Pays de la Loire', '45': 'Centre-Val de Loire', '46': 'Occitanie', '47': 'Nouvelle-Aquitaine',
                        '48': 'Occitanie', '49': 'Pays de la Loire', '50': 'Normandie', '51': 'Grand Est', '52': 'Grand Est', '53': 'Pays de la Loire', '54': 'Grand Est',
                        '55': 'Grand Est', '56': 'Bretagne', '57': 'Grand Est', '58': 'Bourgogne-Franche-ComtÃ©', '59': 'Hauts-de-France', '60': 'Hauts-de-France',
                        '61': 'Normandie', '62': 'Hauts-de-France', '63': 'Auvergne-RhÃ´ne-Alpes', '64': 'Nouvelle-Aquitaine', '65': 'Occitanie', '66': 'Occitanie',
                        '67': 'Grand Est', '68': 'Grand Est', '69': 'Auvergne-RhÃ´ne-Alpes', '70': 'Bourgogne-Franche-ComtÃ©', '71': 'Bourgogne-Franche-ComtÃ©', '72': 'Pays de la Loire',
                        '73': 'Auvergne-RhÃ´ne-Alpes', '74': 'Auvergne-RhÃ´ne-Alpes', '75': 'Ãle-de-France', '76': 'Normandie', '77': 'Ãle-de-France', '78': 'Ãle-de-France',
                        '79': 'Nouvelle-Aquitaine', '80': 'Hauts-de-France', '81': 'Occitanie', '82': 'Occitanie', '83': 'Provence-Alpes-CÃ´te d\'Azur', '84': 'Provence-Alpes-CÃ´te d\'Azur',
                        '85': 'Pays de la Loire', '86': 'Nouvelle-Aquitaine', '87': 'Nouvelle-Aquitaine', '88': 'Grand Est', '89': 'Bourgogne-Franche-ComtÃ©', '90': 'Bourgogne-Franche-ComtÃ©',
                        '91': 'Ãle-de-France', '92': 'Ãle-de-France', '93': 'Ãle-de-France', '94': 'Ãle-de-France', '95': 'Ãle-de-France', '96': 'Outre-mer', '97': 'Outre-mer',
                        '98': 'Outre-mer', '99': 'Outre-mer'
                    }

                    # Comptage des dÃ©partements les plus frÃ©quents dans anomalies
                    top_departments = anomalies['DÃ©partement d\'exercice du PS exÃ©cutant'].value_counts().head(10)

                    # Mappage des dÃ©partements vers les rÃ©gions
                    top_departments_regions = top_departments.index.astype(str).map(departement_to_region)

                    # Comptage des rÃ©gions les plus frÃ©quentes dans anomalies (aprÃ¨s mappage)
                    region_counts = top_departments_regions.value_counts()

                    # Mappage des dÃ©partements aux rÃ©gions
                    department_to_region = top_departments.index.to_series().map(departement_to_region)

                    # Calcul de la somme des pourcentages des dÃ©partements dans chaque rÃ©gion
                    region_percentage = top_departments.groupby(top_departments_regions).sum() / top_departments.sum() * 100

                    # CrÃ©ation du barh chart pour les rÃ©gions
                    plt.figure(figsize=(10, 6))

                    # Choisir un jeu de couleurs stylÃ©
                    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']

                    # Tracer le graphique en barh
                    bars = region_percentage.plot(kind='barh', color=colors, edgecolor='black', linewidth=1.2)

                    # Ajouter des labels sur les barres
                    for index, value in enumerate(region_percentage):
                        # Ajouter l'Ã©tiquette dans la barre, avec la somme des pourcentages des dÃ©partements
                        plt.text(value + 0.1, index, f'{value:.1f}%', va='center', ha='left', fontsize=12, color='black')

                    # Ajouter des titres et des labels
                    plt.xlabel("Somme des pourcentages des dÃ©partements", fontsize=14)
                    plt.ylabel("RÃ©gions", fontsize=14)
                    plt.title("RÃ©partition des rÃ©gions les plus frÃ©quentes dans les anomalies", fontsize=16, fontweight='bold')

                    # Personnaliser les axes et l'apparence
                    plt.xticks(fontsize=12)
                    plt.yticks(fontsize=12)

                    # Ajouter un fond et des bordures stylisÃ©es
                    plt.gca().set_facecolor('whitesmoke')
                    for spine in plt.gca().spines.values():
                        spine.set_linewidth(1.5)
                        spine.set_color('gray')

                    st.pyplot()

                
                with sub_tab3:
                    etablissement_anomalie_id = anomalies['NÂ° PS exÃ©cutant Statistique'].value_counts().idxmax()
                    etablissement_normal_id = normales['NÂ° PS exÃ©cutant Statistique'].value_counts().idxmax()

                    # Filtrer les donnÃ©es pour ces deux Ã©tablissements
                    anomalies_etablissement = anomalies[anomalies['NÂ° PS exÃ©cutant Statistique'] == etablissement_anomalie_id]
                    normales_etablissement = normales[normales['NÂ° PS exÃ©cutant Statistique'] == etablissement_normal_id]

                    # Calculer les remboursements totaux par mois pour anomalies et normales
                    anomalies_mois = anomalies_etablissement.groupby(['AnnÃ©e de remboursement', 'Mois de remboursement'])['DÃ©penses par mois'].sum().reset_index()
                    normales_mois = normales_etablissement.groupby(['AnnÃ©e de remboursement', 'Mois de remboursement'])['DÃ©penses par mois'].sum().reset_index()

                    # Tracer le graphique
                    fig, ax = plt.subplots(figsize=(12, 6))  # CrÃ©er un objet figure et axe
                    sns.lineplot(data=anomalies_mois, x='Mois de remboursement', y='DÃ©penses par mois', label=f'Anomalies ({etablissement_anomalie_id})', color='red', marker='o', ax=ax)
                    sns.lineplot(data=normales_mois, x='Mois de remboursement', y='DÃ©penses par mois', label=f'Normales ({etablissement_normal_id})', color='blue', marker='o', ax=ax)

                    # Ajouter des dÃ©tails au graphique
                    ax.set_title(f'DÃ©penses par mois : {etablissement_anomalie_id} (Anomalies) vs {etablissement_normal_id} (Normales)')
                    ax.set_xlabel('Mois')
                    ax.set_ylabel('DÃ©penses')
                    ax.legend(title='CatÃ©gorie', loc='upper left')
                    ax.set_xticklabels(ax.get_xticks(), rotation=45)
                    ax.grid(True)

                    st.pyplot(fig)

                    # Affichage des Ã©tablissements sÃ©lectionnÃ©s pour confirmation
                    st.write(f"Ã‰tablissement le plus frÃ©quent dans les anomalies : {etablissement_anomalie_id}")
                    st.write(f"Ã‰tablissement le plus frÃ©quent dans les normales : {etablissement_normal_id}")



if __name__ == "__main__":
    main()

